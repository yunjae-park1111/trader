import csv
import json
from datetime import datetime
from .config import logger, generate_columns
from .llm_analyzer import analyze_news_with_gpt
from .price_monitor import start_monitoring_threads
from .telegram_notifier import send_error_notification

def handle_news(data: dict, save_dir: str) -> str:
    """
    ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì‹  â†’ CSV ì €ì¥ ë° ìŠ¤ë ˆë“œ ì‹œì‘
    """
    try:
        news = data["payload"]["news"]
        stock = data["payload"].get("stock", {})

        symbol = news.get("symbol", "")
        timestamp = datetime.fromtimestamp(news["timestamp"] / 1000)
        file_ts = timestamp.strftime("%Y-%m-%d_%H-%M")
        filename = f"{symbol}_{file_ts}.csv"
        filepath = f"{save_dir}/{filename}"

        market_cap = stock.get("marketCap", "")
        
        # GPTë¡œ ë‰´ìŠ¤ ë¶„ì„
        logger.info(f"ğŸ¤– GPT ë¶„ì„ ì‹œì‘: {symbol}")
        llm_result = analyze_news_with_gpt(news)
        
        # ë¶„ì„ ê²°ê³¼ ë¡œê¹…
        logger.info(f"ğŸ“Š ë¶„ì„ ê²°ê³¼ - {symbol}: í‰ì ={llm_result['rating']}, ê°ì„±={llm_result['sentiment']}")
        logger.info(f"ğŸ’¬ ë¶„ì„ ë‚´ìš©: {llm_result['analysis'][:100]}...")
        
        # CSVì— ì €ì¥í•  ë°ì´í„° (ê¸°ì¡´ sentiment_score ëŒ€ì‹  GPT rating ì‚¬ìš©)
        sentiment_score = llm_result['rating']

        row = [symbol, market_cap, 1, sentiment_score]
        row += [""] * (60 * 2 + 60 * 2)

        # CSV íŒŒì¼ ìƒì„±
        with open(filepath, mode="w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(generate_columns())
            writer.writerow(row)
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ ë³„ë„ JSON íŒŒì¼ë¡œë„ ì €ì¥
        analysis_filename = f"{symbol}_{file_ts}_analysis.json"
        analysis_filepath = f"{save_dir}/{analysis_filename}"
        
        analysis_data = {
            "symbol": symbol,
            "timestamp": timestamp.isoformat(),
            "news": news,
            "llm_analysis": llm_result,
            "market_cap": market_cap
        }
        
        with open(analysis_filepath, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {analysis_filename}")
        logger.info(f"[ğŸ“° ì €ì¥ ì™„ë£Œ] {filename}")
        logger.info(f"â³ ê³¼ê±° 60ë¶„ ë°ì´í„° ë¶„ì„ í›„ ì•Œë¦¼ ì˜ˆì •: {symbol}")

        # ê°€ê²© ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œì‘
        start_monitoring_threads(symbol, filepath)

        return filepath

    except Exception as e:
        error_msg = f"ë‰´ìŠ¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}"
        logger.error(f"âŒ {error_msg}")
        send_error_notification("ë‰´ìŠ¤ ì²˜ë¦¬ ì˜¤ë¥˜", error_msg)
        return None
